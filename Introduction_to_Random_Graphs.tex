
\section{Introduction to Inhomogenous Random Graphs}\label{sec: IRG}
In this section, we will review the theory of inhomogenous random graphs developed in \cite{BJR07}. We will introduce the relevant definitions and state, without proof, the main results of \cite{BJR07} which we use in our work.
\begin{definition} \label{def: Generalised vertex space} A \emph{generalised vertex space} is a triple $\mathcal{V}=(\mathcal{S}, m, (\mathbf{v}_N)_{N\geq 1})$, consisting of \begin{itemize}
    \item A separable metric space $\mathcal{S}$, equipped with its Borel $\sigma$-algebra;
    \item A measure $m$ on $\mathcal{S}$, with $m(\mathcal{S}) \in (0, \infty)$; 
    \item A family of random variables $\mathbf{v}_N=(v^{(N)}_1,...,v^{(N)}_{l_N})$ taking values in $\mathcal{S}$, and of potentially random length $l_N$,  such that the empirical measures \begin{equation}
        m_N=\frac{1}{N}\sum_{k=1}^{l_N} \delta_{v^{(N)}_k} \end{equation} converge to $m$ in the weak topology $\mathcal{F}(C_b(\mathcal{S}))$, in probability.

\end{itemize} In the special case where $m(\mathcal{S})=1$ and $l_N=N$, we say that $(\mathcal{S}, m, (\mathbf{v}_N)_{N\geq 1})$ is a \emph{vertex space}. \end{definition}  
\begin{definition}
    A \emph{kernel} is a symmetric, measurable map $k: \mathcal{S}\times \mathcal{S} \rightarrow [0, \infty).$ We say that $k$ is \emph{positive} if, for all distinct $x,y \in S$, $k(x,y)>0$. 
    \end{definition} This is sufficient for our results, and is a slightly requirement stronger than the notion of irreducibility in \cite{BJR07}; this difference allows us to eliminate the possibility of exceptional sets of measure $0$. \begin{definition}[Inhomogenous random graphs]\label{definition of GN} Given a kernel $k$ and a generalised vertex space $\mathcal{V}$, we let
    $G^N$ be a random graph on $\{1, 2,..,N\}$ given as follows. Conditional on the values of $\mathbf{v}_N$, the edge $e=(ij)$ is included with probability \begin{equation}
        p_{ij}=1-\exp\left(-\frac{k(v^{(N)}_i,v^{(N)}_j)}{N} \right)
    \end{equation} and such that the presence of different edges is (conditionally) independent. We write $G^N\sim\mathcal{G}^\mathcal{V}(N,k)$. We also consider the \emph{vertex data}  $\mathbf{v}_N=(v^{(N)}_i)_{i=1}^N$ to be part of the data of $G^N_t$, so that an equality of random graphs $G=G'$ includes the equality of the vertex data.
\end{definition} To treat a general class of kernels $k$, additional regularity is required, to prevent pathologies. This is the content of the following defintion: \begin{definition}[Graphical Kernel]
    We say that a kernel $k$ on a vertex space $\mathcal{V}=(\mathcal{S}, m, (\mathbf{v}_N)_{N\geq 1})$ is \emph{graphical} if the following hold. 
    \begin{enumerate}[label=\roman{*}).]
        \item $k$ is almost everywhere continuous on $\mathcal{S}\times\mathcal{S};$
        \item $k \in L^1(\mathcal{S}\times \mathcal{S}, m \times m)$;
        \item If $G^N \sim \mathcal{G}^\mathcal{V}(N,k)$, then
        \begin{equation}
            \frac{1}{N}\mathbb{E}\left[e\left(G^N\right)\right]\rightarrow \frac{1}{2}\int_{\mathcal{S}\times \mathcal{S}} k(v,w)m(dv)m(dw)
        \end{equation} where $e(\cdot)$ denotes the number of edges of the graph.
    \end{enumerate}
\end{definition}  \begin{definition}
 Given a graph $G$, we write $\mathcal{C}_j(G): j=1, 2...$ for the connected components of $G$, in decreasing order of their sizes $\#\mathcal{C}_j(G)=C_j(G)$. If there are fewer than $j$ connected components, then $\mathcal{C}_j(G)=\emptyset$ and $C_j(G)=0$.
\end{definition}The phase transition is given in terms of the convolution operator
\begin{equation}\label{eq: T}
       (T f)(v)=\int_{\mathbb{R}^d} k(v,w)f(w)m(dw) 
   \end{equation} for functions $f$ such that the right-hand side is defined (i.e., finite or $+\infty$) for $m$-almost all $v$; for instance, if $f\ge 0$ then $Tf$ is well-defined, possibly taking the value $\infty$. We define \begin{equation} \|T\|=\sup\{\|Tf\|_{L^2(m)}: \|f\|_{L^2(m)}\le 1, f\ge 0\}. \end{equation} If $T$ defines a bounded linear map from $L^2(m)$ to itself, then $\|T\|$ is precisely its operator norm in this setting; otherwise, $\|T\|=\infty.$ It is straightforward to show that if $k\in L^2(S\times S, m\times m)$ then $T: L^2(m)\rightarrow L^2(m)$ is a Hilbert-Schmidt operator, and that $\|T\|_\text{HS}=\|k\|_{L^2(m)}<\infty$. In this case, $\|T\|$ is certainly finite, and is the operator norm of $T: L^2(m)\rightarrow L^2(m)$. The example of interest to us will fall into this case. \bigskip\\  The analysis of the random graphs uses a branching process, similar to that used in the standard analysis of Erd\H{o}s-R\'enyi graphs. Many quantities of the graph can be expressed in terms of the `survival probability' $\rho(k, v)$ when the data $v$ of the first vertex is given. To avoid the unnecessary complication of making this into a precise definition, we use the following characterisation, which is equivalent by \cite[Theorem 6.2]{BJR07}.
   \begin{lemma}\label{lemma: survival function}
       Let $k$ be a positive kernel on a generalised vertex space $\mathcal{V}$, such that $k \in L^1(\mathcal{S}\times \mathcal{S}, m \times m)$, and such that, for all $v,$ \begin{equation} \label{eq: BJR 51}
           \int_S k(v,w)m(dw)<\infty.
       \end{equation} Consider the nonlinear fixed-point equation 
      \begin{equation} \label{eq: nonlinear fixed point equation} 
        \forall v \in S,\hspace{1cm}  {\rho}(v)=1-e^{-(T{\rho})(v)}
      \end{equation} where $T$ is the convolution operator (\ref{eq: T}). Then (\ref{eq: nonlinear fixed point equation}) has a maximal solution $\rho_k(v)=\rho(k;v)$; that is, for any other solution $\tilde{\rho}$, \begin{equation}
          \forall v \in S, \hspace{1cm} \tilde{\rho}(v)\leq \rho(k,v).
      \end{equation} It therefore follows that $0\leq \rho_k(v)\leq 1$ for all $v$. The maximal solution is necessarily unique, and so this uniquely defines $\rho_k.$ Moreover, we have the following dichotomy:
      \begin{enumerate}[label=\roman{*}).]
          \item If $\|T\|\leq 1$, then $\rho(k, v)=0$ for all $v$;
          \item If $\|T\|> 1$, then $\rho(k, v)>0$ for all $v$.
      \end{enumerate} This can be stated dynamically as follows. Consider the survival function `at time $t$', given by $\rho(tk,v)$, which we will write throughout as $\rho_t(v)$. Then 
      \begin{itemize}
          \item If $t\leq \|T\|^{-1}$, then $\rho_t(v)=0$ for all $v$;
          \item If $t>\|T\|^{-1}$, then $\rho_t(v)>0$ for all $v$.
      \end{itemize}
      
   \end{lemma} We can now state the main results on the phase transition, given by \cite[Theorem 3.1 and Corollary 3.2]{BJR07}.
   \begin{theorem}[Phase Transition]\label{thrm: RG1} Let $k$ be a graphical and positive kernel for a vertex space $\mathcal{V}$, with $0<\|T\|< \infty.$ Let $G^N\sim \mathcal{G}^\mathcal{V}(N, k)$ be random graphs on a common probability space. Then we have the convergence \begin{equation}
       \frac{1}{N}C_1(G^N_t)\rightarrow \int_{\mathcal{S}} \rho(tk, v) m(dv) \hspace{1cm} \text{in probability.}
   \end{equation}
   Therefore, if $(G^N_t)_{t\geq 0}$ is a dynamic family of random graphs $
       G^N_t \sim \mathcal{G}^\mathcal{V}(N, tk)$, then we have the following dichotomy:  \begin{enumerate}[label=\roman{*}).]
       \item If $t\leq \|T\|^{-1}$, then there is no giant component, in particular \begin{equation}
           \frac{C_1(G^N_t)}{N} \rightarrow 0
       \end{equation} in probability.
       \item If $t>\|T\|^{-1}$, then there is a giant component: there exists $c=c(t)>0$ such that
       \begin{equation}
           \mathbb{P}(C_1(G^N_t)>cN)\rightarrow 1.
       \end{equation}
   \end{enumerate}\end{theorem}
   \begin{remark} Following \cite{BJR07}, based on this dichotomy, we say that \begin{enumerate}[label=\roman{*}).]
       \item $G^N$ is \emph{subcritical} if $\|T\|<1;$
       \item $G^N$ is \emph{critical} if $\|T\|=1;$
       \item $G^N$ is \emph{supercritical} if $\|T\|>1.$
   \end{enumerate} \end{remark} We also have the following result, which implies the uniqueness of the giant component \cite[Theorem 3.6]{BJR07}. This result considers clusters of a scale $\xi_N\ll N$, excluding the largest; we term these \emph{mesoscopic} clusters.
   \begin{theorem}\label{thrm: RG2} Let $G^N\sim \mathcal{G}^\mathcal{V}(N, k)$, for a (generalised) vertex space $\mathcal{V}$ and an positive graphical kernel $k$. Let $\xi_N$ be a sequence with  \begin{equation}
       \xi_N\rightarrow \infty; \hspace{1cm} \frac{\xi_N}{N}\rightarrow 0.
   \end{equation} Then \begin{equation}
       \frac{1}{N}\sum_{j\geq 2: C_j(G^N)\geq \xi_N}C_j(G^N) \rightarrow 0
   \end{equation} in probability. \end{theorem}   We will also make use of the following monotonicity and continuity properties, from \cite[Theorem 6.4]{BJR07}.
   \begin{theorem}\label{thrm: continuity of rho} Let $k$ be a kernel on a vertex space $\mathcal{V}$, and let $\rho_t(\cdot)=\rho(tk,\cdot)$ be the survival function defined above. Then the map $t\mapsto \rho_t(\cdot)$ is monotonically increasing, in the sense that for all $0\leq s \leq t$ and for all $v$, $\rho_s(v)\le \rho_t(v).$ We also have the following continuity property. Let $t_n\rightarrow t$ be a monotone sequence, either increasing or decreasing. Then \begin{equation}
       \rho_{t_n}(v)\rightarrow \rho_t(v) \hspace{1cm} \text{for $m$- almost all }v, \text{ and}
   \end{equation} \begin{equation}
       \int_{\mathcal{S}}\rho_{t_n}(v)m(dv)\rightarrow \int_{\mathcal{S}}\rho_t(v)m(dv).
   \end{equation} \end{theorem} The final result which we will need is a `duality' result, connecting the supercritical and subcritical behaviours. This is given by \cite[Theorem 12.1]{BJR07}.
   \begin{theorem}\label{thrm: coupling supercritical and subcritical} Let $k$ be an positive graphical kernel on a generalised vertex space $\mathcal{V}$, such that $\|T\|>1$. Let $G^N \sim \mathcal{G}^\mathcal{V}(N, k)$, and form $\widetilde{G}^N$ by deleting all vertexes in the largest component $\mathcal{C}_1(G^N).$ Then, defined on the same underlying probability space, there is a generalised vertex space $\widehat{\mathcal{V}}=(\mathcal{S}, \widehat{m}, (\mathbf{w}_N)_{N\geq 1})$ with \begin{equation}
       \widehat{m}(dv)=(1-\rho(k;v))m(dv)
   \end{equation} and such that $\mathbf{w}_N$ is an enumeration of those $v_i$ not belonging to the component $\mathcal{C}_1(G^N)$, and a random graph $\widehat{G}^N \sim \mathcal{G}^{\widehat{\mathcal{V}}}(N,k)$ such that \begin{equation}
       \mathbb{P}(\widetilde{G}^N=\widehat{G}^N)\rightarrow 1.
   \end{equation}  Furthermore, if $k\in L^2(\mathcal{S}\times \mathcal{S}, m\times m)$, then $\widehat{G}^N$ is subcritical.\end{theorem} We emphasise here that we have defined the equality $\widetilde{G}^N=\widehat{G}^N$ includes equality of the velocities $v_i$ associated to each vertex; this follows from the construction in \cite{BJR07}, since the velocities $\mathbf{w}_N$ associated to $\widehat{G}^N$ are exactly those $v_i$ not belonging to the giant component. This generalises the standard `duality result' of Bollob\'as \cite{BB84} for Erd\H{o}s-R\'enyi graphs. 